ICLR 2019 Submissions
=====================
I did an initial pass of open review and some of the ICLR submissions that we posted. Here are the ones that caught my eye. I am mostly thinking about
interpretability, robustness, privacy etc these days so I lean heavily towards these areas. 


### Theory/Stability 
* [Stable Recurrent Models](https://openreview.net/forum?id=Hygxb2CqKm)

* [The Singular Values of Convolutional Layers](https://openreview.net/forum?id=rJevYoA9Fm)

* [In search of theoretically grounded pruning](https://openreview.net/forum?id=SkfQAiA9YX)

### Miscellaneous Interesting Looking ones
* [Learning a SAT Solver from Single-Bit Supervision](https://openreview.net/forum?id=HJMC_iA5tm)

* [Overfitting Detection of Deep Neural Networks without a Hold Out Set](https://openreview.net/forum?id=B1lKtjA9FQ)

* [Detecting Memorization in ReLU Networks](https://openreview.net/forum?id=HJeB0sC9Fm)

* [Learning to Augment Influential Data](https://openreview.net/forum?id=BygIV2CcKm)

* [Do Deep Generative Models Know What They Don't Know?](https://openreview.net/forum?id=H1xwNhCcYm)

### Systems

* [Dopamine: A Research Framework for Deep Reinforcement Learning](https://openreview.net/forum?id=ByG_3s09KX)

### Verification
* [Robustness Certification with Refinement](https://openreview.net/forum?id=HJgeEh09KQ)

* [Verification of Non-Linear Specifications for Neural Networks](https://openreview.net/forum?id=HyeFAsRctQ)


### Privacy, Federated Learning, Differential Privacy

* [Differentially Private Federated Learning: A Client Level Perspective](https://openreview.net/forum?id=SkVRTj0cYQ)


### Why does a phenomenon work type papers (empirical and theory)
* [Pooling Is Neither Necessary nor Sufficient for Appropriate Deformation Stability in CNNs](https://openreview.net/forum?id=HJeuOiRqKQ)

* [Why do deep convolutional networks generalize so poorly to small image transformations?](https://openreview.net/forum?id=HJxYwiC5tm)

* [How Training Data Affect the Accuracy and Robustness of Neural Networks for Image Classification.](https://openreview.net/forum?id=SyxG13R9Km)

### Bias

* [Identifying Bias in AI using Simulation](https://openreview.net/forum?id=BJf_YjCqYX)


### Interpretability

* [Visualizing and Understanding Generative Adversarial Networks.](https://openreview.net/forum?id=Hyg_X2C5FX)

* [Can I trust you more? Model-Agnostic Hierarchical Explanations](https://openreview.net/pdf?id=rkMD73A5FX)

* [Exploring the interpretability of LSTM neural networks over multi-variable data](https://openreview.net/forum?id=HklVMnR5tQ)

* [How Important is a Neuron](https://openreview.net/forum?id=SylKoo0cKm)

* [Feature Attribution As Feature Selection](https://openreview.net/forum?id=H1lS8oA5YQ)

* [Learning Global Additive Explanations for Neural Nets using Model Distillation.](https://openreview.net/forum?id=SJl8J30qFX)

* [Visualizing and Discovering behavioral weaknesses in deep reinforcement learning.](https://openreview.net/pdf?id=BJf9k305Fm)

* [Interpreting Layered Neural Networks via Hierarchical Modular Representation](https://openreview.net/forum?id=Hyed4i05KX)

* [Interpreting Deep Neural Network: Fast Object Localization via sensitivity analysis.](https://openreview.net/forum?id=rkzUYjCcFm)

* [Explaining Neural Networks Semantically and Quantitatively.](https://openreview.net/forum?id=SJfWKsC5K7)

* [Classifier-agnostic saliency map extraction.](https://openreview.net/forum?id=BJxbYoC9FQ)

* [L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data](https://openreview.net/forum?id=S1E3Ko09F7)

* [Interpretable Continual Learning.](https://openreview.net/forum?id=S1g9N2A5FX)

* [Looking Inside the black box: assessing the modular structure of deep generative models with counterfactuals.](https://openreview.net/forum?id=Byldr3RqKX)

* [KnockoffGAN: Generating Knockoffs for Feature Selection using Generative Adversarial Networks.](https://openreview.net/forum?id=ByeZ5jC5YQ)

* [Bias also matters: bias attribution for deep neural network explanation.](https://openreview.net/forum?id=B1xeyhCctQ)